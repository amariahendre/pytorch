{"cells":[{"source":"import torch\nimport numpy as np","metadata":{"executionTime":14,"lastSuccessfullyExecutedCode":"import torch\nimport numpy as np"},"cell_type":"code","id":"6d0aba00-0ce4-4511-8dc6-39f023c6b665","execution_count":392,"outputs":[]},{"source":"## Create tensors","metadata":{},"cell_type":"markdown","id":"13c3048d-ebc3-45db-a748-3fbffc1e4e02"},{"source":"A tensor is a mathematical object that represents a multi-dimensional array of numerical values. \nIn machine learning and deep learning, tensors are used to represent data inputs and outputs, as well as the weights and biases of neural networks. Tensors enable efficient computation of complex mathematical operations on large datasets, making them an essential tool in modern data science.","metadata":{},"cell_type":"markdown","id":"4c13a213-b5ca-4bdb-a84f-1df977879e6e"},{"source":"# scalar\nscalar = torch.tensor(7)\nscalar.ndim, scalar.item()","metadata":{"executionTime":15,"lastSuccessfullyExecutedCode":"# scalar\nscalar = torch.tensor(7)\nscalar.ndim, scalar.item()"},"cell_type":"code","id":"5117664c-7da8-4766-95c7-1d0d66855191","execution_count":393,"outputs":[{"output_type":"execute_result","execution_count":393,"data":{"text/plain":"(0, 7)"},"metadata":{}}]},{"source":"# vector\nvector = torch.tensor([7,7])\nvector.ndim, vector.shape","metadata":{"executionTime":91,"lastSuccessfullyExecutedCode":"# vector\nvector = torch.tensor([7,7])\nvector.ndim, vector.shape"},"cell_type":"code","id":"8a9b18f9-37d9-4382-bf63-4af1624e3f57","execution_count":394,"outputs":[{"output_type":"execute_result","execution_count":394,"data":{"text/plain":"(1, torch.Size([2]))"},"metadata":{}}]},{"source":"# MATRIX\nMATRIX = torch.tensor([[7,8],[9,10]])\nMATRIX.ndim, MATRIX.shape, MATRIX[0]","metadata":{"executionTime":20,"lastSuccessfullyExecutedCode":"# MATRIX\nMATRIX = torch.tensor([[7,8],[9,10]])\nMATRIX.ndim, MATRIX.shape, MATRIX[0]"},"cell_type":"code","id":"3f5e59ed-31fc-4ad9-87ff-c695031c92a7","execution_count":395,"outputs":[{"output_type":"execute_result","execution_count":395,"data":{"text/plain":"(2, torch.Size([2, 2]), tensor([7, 8]))"},"metadata":{}}]},{"source":"# tensor\nTENSOR = torch.tensor([[[1,2,3],[3,6,9],[2,5,4]]])\nTENSOR.ndim, TENSOR.shape, TENSOR[0], TENSOR[0][0], TENSOR[0][0][0]","metadata":{"executionTime":13,"lastSuccessfullyExecutedCode":"# tensor\nTENSOR = torch.tensor([[[1,2,3],[3,6,9],[2,5,4]]])\nTENSOR.ndim, TENSOR.shape, TENSOR[0], TENSOR[0][0], TENSOR[0][0][0]"},"cell_type":"code","id":"fdf5e2d4-d1af-47fc-ab18-17eeb07abf27","execution_count":396,"outputs":[{"output_type":"execute_result","execution_count":396,"data":{"text/plain":"(3,\n torch.Size([1, 3, 3]),\n tensor([[1, 2, 3],\n         [3, 6, 9],\n         [2, 5, 4]]),\n tensor([1, 2, 3]),\n tensor(1))"},"metadata":{}}]},{"source":"# Random tensors \nrandom_tensor = torch.rand(3,4)\nrandom_tensor, random_tensor.ndim","metadata":{"executionTime":10,"lastSuccessfullyExecutedCode":"# Random tensors \nrandom_tensor = torch.rand(3,4)\nrandom_tensor, random_tensor.ndim"},"cell_type":"code","id":"99c9fe90-c73a-41b7-8ce4-e8a5c643dfca","execution_count":397,"outputs":[{"output_type":"execute_result","execution_count":397,"data":{"text/plain":"(tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n         [0.8854, 0.5739, 0.2666, 0.6274],\n         [0.2696, 0.4414, 0.2969, 0.8317]]),\n 2)"},"metadata":{}}]},{"source":"# random tensor with similar shape to an image tensor\nrandom_image_size_tensor = torch.rand(size = (224,224,3))\nrandom_image_size_tensor.shape, random_image_size_tensor.ndim","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# random tensor with similar shape to an image tensor\nrandom_image_size_tensor = torch.rand(size = (224,224,3))\nrandom_image_size_tensor.shape, random_image_size_tensor.ndim"},"cell_type":"code","id":"f6e8ea33-6606-4104-832a-2a346e780a1b","execution_count":398,"outputs":[{"output_type":"execute_result","execution_count":398,"data":{"text/plain":"(torch.Size([224, 224, 3]), 3)"},"metadata":{}}]},{"source":"# tensors with zeros\nzeros = torch.zeros(size=(3,4))\nzeros, zeros*random_tensor, zeros.dtype","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# tensors with zeros\nzeros = torch.zeros(size=(3,4))\nzeros, zeros*random_tensor, zeros.dtype"},"cell_type":"code","id":"aa4028a0-ebfc-4e0c-b840-b7e5837e63fd","execution_count":399,"outputs":[{"output_type":"execute_result","execution_count":399,"data":{"text/plain":"(tensor([[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]),\n tensor([[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]),\n torch.float32)"},"metadata":{}}]},{"source":"# tesors with ones\nones = torch.ones(size=(3,4))\nones","metadata":{"executionTime":67,"lastSuccessfullyExecutedCode":"# tesors with ones\nones = torch.ones(size=(3,4))\nones"},"cell_type":"code","id":"71018327-4dbb-4256-baa5-684a899ee54c","execution_count":400,"outputs":[{"output_type":"execute_result","execution_count":400,"data":{"text/plain":"tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])"},"metadata":{}}]},{"source":"# create a rage of tensors\ntorch_arange = torch.arange(start=1, end=1000, step=85)\ntorch_arange","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# create a rage of tensors\ntorch_arange = torch.arange(start=1, end=1000, step=85)\ntorch_arange"},"cell_type":"code","id":"6aa7d518-72fc-450d-8e51-ae738158a28c","execution_count":401,"outputs":[{"output_type":"execute_result","execution_count":401,"data":{"text/plain":"tensor([  1,  86, 171, 256, 341, 426, 511, 596, 681, 766, 851, 936])"},"metadata":{}}]},{"source":"# create tensors like\ntensor_like = torch.zeros_like(input=torch_arange)\ntensor_like","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# create tensors like\ntensor_like = torch.zeros_like(input=torch_arange)\ntensor_like"},"cell_type":"code","id":"bcebbafc-089f-4f73-9257-2749dfdc4b33","execution_count":402,"outputs":[{"output_type":"execute_result","execution_count":402,"data":{"text/plain":"tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}}]},{"source":"## Tensor datatypes","metadata":{},"cell_type":"markdown","id":"1009aa4e-d986-41af-9da9-e577a7933115"},{"source":"float_32_tensor = torch.tensor([3.0,8.9,6.7], dtype = None, device=None, requires_grad=False)\nfloat_32_tensor, float_32_tensor.dtype","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"float_32_tensor = torch.tensor([3.0,8.9,6.7], dtype = None, device=None, requires_grad=False)\nfloat_32_tensor, float_32_tensor.dtype"},"cell_type":"code","id":"477372c0-8a36-4272-bdac-6fad4e98d6fe","execution_count":403,"outputs":[{"output_type":"execute_result","execution_count":403,"data":{"text/plain":"(tensor([3.0000, 8.9000, 6.7000]), torch.float32)"},"metadata":{}}]},{"source":"Note:\n- dtype: specifies the data type of the tensor or variable. PyTorch supports various data types, such as float, integer, and boolean, each represented by a different dtype.\n- device: specifies the device on which the tensor or variable resides. PyTorch supports different devices, such as CPU or GPU, and the device argument allows you to specify which device to use. If device is not specified, PyTorch will use the default device, which is typically the CPU.\n- requires_grad: specifies whether or not the tensor or variable should have its gradients computed during backpropagation. If requires_grad is set to True, then the tensor or variable will have a gradient attribute that stores the gradients computed during backpropagation. If requires_grad is set to False, then the tensor or variable will not have a gradient attribute and its gradients will not be computed during backpropagation.","metadata":{},"cell_type":"markdown","id":"98aeff4e-0cbc-40ad-9524-e0fb5fabdfc2"},{"source":"float_16_tensor = float_32_tensor.type(torch.float16)\nfloat_16_tensor, float_16_tensor.dtype","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"float_16_tensor = float_32_tensor.type(torch.float16)\nfloat_16_tensor, float_16_tensor.dtype"},"cell_type":"code","id":"ee78e3ed-4994-49bc-ac42-789b74b06213","execution_count":404,"outputs":[{"output_type":"execute_result","execution_count":404,"data":{"text/plain":"(tensor([3.0000, 8.8984, 6.6992], dtype=torch.float16), torch.float16)"},"metadata":{}}]},{"source":"## Tensor attributes","metadata":{},"cell_type":"markdown","id":"b3b825c9-4a20-430e-8a8c-963e2d62f865"},{"source":"**3 big errors you will run into Pytorch and deep learning:** \n- tensors not right datatype\n- tensors not rights shape\n- tensors not on the right device","metadata":{},"cell_type":"markdown","id":"ef1448a8-268e-4a08-b6a7-0e7a624a3f99"},{"source":"some_tensor = torch.rand(3,4)\nsome_tensor.dtype, some_tensor.shape, some_tensor.device","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"some_tensor = torch.rand(3,4)\nsome_tensor.dtype, some_tensor.shape, some_tensor.device"},"cell_type":"code","id":"dbb12a07-96c9-42bd-a80a-b0d5dabbc23e","execution_count":405,"outputs":[{"output_type":"execute_result","execution_count":405,"data":{"text/plain":"(torch.float32, torch.Size([3, 4]), device(type='cpu'))"},"metadata":{}}]},{"source":"## Tensor Operations","metadata":{},"cell_type":"markdown","id":"c77af34d-9794-40a8-a4d9-6227d01542d0"},{"source":"Tensor operations include:\n- Addition and subtraction: This involves adding or subtracting two tensors of the same shape element-wise.\n- Multiplication: This involves multiplying two tensors, which can be done element-wise or using matrix multiplication.\n- Division: This involves element-wise division of two input tensors.","metadata":{},"cell_type":"markdown","id":"648a4625-675c-45e1-a35e-bb8a9909ac5a"},{"source":"tensor = torch.tensor([1,2,3])","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"tensor = torch.tensor([1,2,3])"},"cell_type":"code","id":"eb419f94-f3fe-4059-902d-189ae3f7270c","execution_count":406,"outputs":[]},{"source":"tensor + 10","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"tensor + 10"},"cell_type":"code","id":"bf9d154d-93b3-4354-b289-6cb4da477485","execution_count":407,"outputs":[{"output_type":"execute_result","execution_count":407,"data":{"text/plain":"tensor([11, 12, 13])"},"metadata":{}}]},{"source":"# PyTorch in-build functions\ntorch.add(tensor, 10)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# PyTorch in-build functions\ntorch.add(tensor, 10)"},"cell_type":"code","id":"43cf88a1-9b21-41fe-9d4c-08f1bbcf3476","execution_count":408,"outputs":[{"output_type":"execute_result","execution_count":408,"data":{"text/plain":"tensor([11, 12, 13])"},"metadata":{}}]},{"source":"tensor - 10","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"tensor - 10"},"cell_type":"code","id":"f2abe8d8-3b59-4574-bb99-d6310ef7fa75","execution_count":409,"outputs":[{"output_type":"execute_result","execution_count":409,"data":{"text/plain":"tensor([-9, -8, -7])"},"metadata":{}}]},{"source":"# PyTorch in-build functions\ntorch.sub(tensor, 10)","metadata":{"executionTime":88,"lastSuccessfullyExecutedCode":"# PyTorch in-build functions\ntorch.sub(tensor, 10)"},"cell_type":"code","id":"94b1aecf-1bb1-4c56-ab70-b96d5ed32bcd","execution_count":410,"outputs":[{"output_type":"execute_result","execution_count":410,"data":{"text/plain":"tensor([-9, -8, -7])"},"metadata":{}}]},{"source":"tensor * 10","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"tensor * 10"},"cell_type":"code","id":"2d0226f7-5b41-497d-a1c4-c9a3dd00aa4a","execution_count":411,"outputs":[{"output_type":"execute_result","execution_count":411,"data":{"text/plain":"tensor([10, 20, 30])"},"metadata":{}}]},{"source":"# PyTorch in-build functions\ntorch.mul(tensor, 10)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# PyTorch in-build functions\ntorch.mul(tensor, 10)"},"cell_type":"code","id":"4cc35748-3a45-4571-b5c5-5e7265ab4672","execution_count":412,"outputs":[{"output_type":"execute_result","execution_count":412,"data":{"text/plain":"tensor([10, 20, 30])"},"metadata":{}}]},{"source":"tensor/10","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"tensor/10"},"cell_type":"code","id":"e1d195a6-1840-417f-b028-626be8c62bce","execution_count":413,"outputs":[{"output_type":"execute_result","execution_count":413,"data":{"text/plain":"tensor([0.1000, 0.2000, 0.3000])"},"metadata":{}}]},{"source":"# PyTorch in-build functions\ntorch.div(tensor, 10)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# PyTorch in-build functions\ntorch.div(tensor, 10)"},"cell_type":"code","id":"9aa49a30-0f4e-42a9-811e-2665dde4ef44","execution_count":414,"outputs":[{"output_type":"execute_result","execution_count":414,"data":{"text/plain":"tensor([0.1000, 0.2000, 0.3000])"},"metadata":{}}]},{"source":"# Matric multiplication\n\n# element wise\ntw = tensor*tensor\n\n# dot product\ntm = torch.matmul(tensor, tensor)\n\ntw, tm","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Matric multiplication\n\n# element wise\ntw = tensor*tensor\n\n# dot product\ntm = torch.matmul(tensor, tensor)\n\ntw, tm"},"cell_type":"code","id":"2f846faf-d2bb-4622-a775-07adf7cfaf55","execution_count":415,"outputs":[{"output_type":"execute_result","execution_count":415,"data":{"text/plain":"(tensor([1, 4, 9]), tensor(14))"},"metadata":{}}]},{"source":"%%time\nvalue = 0\nfor i in range (len(tensor)):\n    value += tensor[i]*tensor[i]\nprint(value)","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"%%time\nvalue = 0\nfor i in range (len(tensor)):\n    value += tensor[i]*tensor[i]\nprint(value)"},"cell_type":"code","id":"d7eae942-678b-4514-bd91-93a28dac22de","execution_count":416,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor(14)\nCPU times: user 1.08 ms, sys: 76 µs, total: 1.15 ms\nWall time: 587 µs\n"}]},{"source":"%%time\ntorch.matmul(tensor, tensor)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"%%time\ntorch.matmul(tensor, tensor)"},"cell_type":"code","id":"efaebc8b-5245-4bcf-bc83-46f1254b2847","execution_count":417,"outputs":[{"output_type":"stream","name":"stdout","text":"CPU times: user 0 ns, sys: 828 µs, total: 828 µs\nWall time: 431 µs\n"},{"output_type":"execute_result","execution_count":417,"data":{"text/plain":"tensor(14)"},"metadata":{}}]},{"source":"# inner dimension must match\n# torch.matmul(torch.rand(3,2), torch.rand(3,2)) #RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\ntorch.matmul(torch.rand(3,2), torch.rand(2,4)).shape # shape = outer dimension","metadata":{"executionTime":9,"lastSuccessfullyExecutedCode":"# inner dimension must match\n# torch.matmul(torch.rand(3,2), torch.rand(3,2)) #RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\ntorch.matmul(torch.rand(3,2), torch.rand(2,4)).shape # shape = outer dimension"},"cell_type":"code","id":"259ae382-bbef-4862-86b0-1fb03ee50487","execution_count":418,"outputs":[{"output_type":"execute_result","execution_count":418,"data":{"text/plain":"torch.Size([3, 4])"},"metadata":{}}]},{"source":"# shapes for matrix multiplication\ntensor_A = torch.tensor([[1,2],[3,4],[5,6]])\ntensor_B = torch.tensor([[7,8],[9,10],[11,12]])\ntorch.matmul(tensor_A,tensor_B.T) #manipulate the shape of tensor_B by transpose","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# shapes for matrix multiplication\ntensor_A = torch.tensor([[1,2],[3,4],[5,6]])\ntensor_B = torch.tensor([[7,8],[9,10],[11,12]])\ntorch.matmul(tensor_A,tensor_B.T) #manipulate the shape of tensor_B by transpose"},"cell_type":"code","id":"24768680-59be-4ef4-a1ef-2135be0d70f5","execution_count":419,"outputs":[{"output_type":"execute_result","execution_count":419,"data":{"text/plain":"tensor([[ 23,  29,  35],\n        [ 53,  67,  81],\n        [ 83, 105, 127]])"},"metadata":{}}]},{"source":"## Tensor agrregation","metadata":{},"cell_type":"markdown","id":"0d6eae18-8dfc-4100-8048-8875c1e27578"},{"source":"x = torch.arange(1,100,10)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"x = torch.arange(1,100,10)"},"cell_type":"code","id":"ac8ed36a-0fb9-4bca-b1e1-dd34b241df51","execution_count":420,"outputs":[]},{"source":"# find the min\ntorch.min(x), x.min()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# find the min\ntorch.min(x), x.min()"},"cell_type":"code","id":"5c5f79be-2809-4560-8c05-6b88f22eab58","execution_count":421,"outputs":[{"output_type":"execute_result","execution_count":421,"data":{"text/plain":"(tensor(1), tensor(1))"},"metadata":{}}]},{"source":"# find the max\ntorch.max(x), x.max()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# find the max\ntorch.max(x), x.max()"},"cell_type":"code","id":"03132c32-e631-40b5-a34c-9fc01e6a488f","execution_count":422,"outputs":[{"output_type":"execute_result","execution_count":422,"data":{"text/plain":"(tensor(91), tensor(91))"},"metadata":{}}]},{"source":"# finding the mean requires a float32 tensor\ntorch.mean(x.type(torch.float32)) , x.type(torch.float32).mean()","metadata":{"executionTime":7,"lastSuccessfullyExecutedCode":"# finding the mean requires a float32 tensor\ntorch.mean(x.type(torch.float32)) , x.type(torch.float32).mean()"},"cell_type":"code","id":"f05410a7-9838-4db7-a7a1-7c333cf49042","execution_count":423,"outputs":[{"output_type":"execute_result","execution_count":423,"data":{"text/plain":"(tensor(46.), tensor(46.))"},"metadata":{}}]},{"source":"# find the sum\ntorch.sum(x), x.sum()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# find the sum\ntorch.sum(x), x.sum()"},"cell_type":"code","id":"f0b0c980-68b1-4abf-af3a-255f7ab09167","execution_count":424,"outputs":[{"output_type":"execute_result","execution_count":424,"data":{"text/plain":"(tensor(460), tensor(460))"},"metadata":{}}]},{"source":"# finding the positional min and max\nx.argmin(), x.argmax()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# finding the positional min and max\nx.argmin(), x.argmax()"},"cell_type":"code","id":"cb72f143-81b7-41fb-b8db-a52f48f15e69","execution_count":425,"outputs":[{"output_type":"execute_result","execution_count":425,"data":{"text/plain":"(tensor(0), tensor(9))"},"metadata":{}}]},{"source":"## Reshaping, stacking, squeezing and unsqueezing, permuting tensors","metadata":{},"cell_type":"markdown","id":"44a84677-00a1-4c2e-a507-ed9295745431"},{"source":"Reshaping, stacking, squeezing, and unsqueezing are common operations performed on tensors in deep learning and machine learning.\n\nReshaping: Reshaping a tensor means changing its shape while keeping the number of elements the same. This operation is also called flattening or raveling. To reshape a tensor, you need to specify the new shape using the reshape() method. For example, if you have a tensor a of shape (2,3,4), you can reshape it to a tensor of shape (3,8) using a.reshape(3,8).\n\nStacking: Stacking two or more tensors along a new dimension is called stacking. This operation is useful for combining tensors of the same shape or stacking batches of data. To stack tensors, you can use the stack() method. For example, if you have two tensors a and b of shape (2,3) and you want to stack them along a new dimension, you can use torch.stack([a,b], dim=0).\n\nSqueezing: Squeezing a tensor means removing any dimensions or axes that have a length of 1. This operation is useful for removing unnecessary dimensions from a tensor. To squeeze a tensor, you can use the squeeze() method. For example, if you have a tensor a of shape (1,2,1,3,1), you can squeeze it to a tensor of shape (2,3) using a.squeeze().\n\nUnsqueezing: Unsqueezing is the opposite of squeezing. It means adding a new dimension or axis with a length of 1 to a tensor. This operation is useful for broadcasting tensors of different shapes. To unsqueeze a tensor, you can use the unsqueeze() method. For example, if you have a tensor a of shape (2,3) and you want to unsqueeze it along a new dimension, you can use a.unsqueeze(dim=0) to get a tensor of shape (1,2,3).\n\nPermuting: The permute() method takes a tuple of integers that represents the new order of dimensions. Each integer in the tuple corresponds to the index of the current dimension that should be moved to the new position. For example, if you have a tensor a of shape (2,3,4) and you want to swap the first and second dimensions, you can use a.permute(1,0,2).","metadata":{},"cell_type":"markdown","id":"0007cf23-e4d3-4f7e-8ed7-a63dd8128d2c"},{"source":"x = torch.arange(1.,11.)\nx, x.shape","metadata":{"executionTime":9,"lastSuccessfullyExecutedCode":"x = torch.arange(1.,11.)\nx, x.shape"},"cell_type":"code","id":"e67be552-025c-4028-85c3-a5be864b7dd8","execution_count":426,"outputs":[{"output_type":"execute_result","execution_count":426,"data":{"text/plain":"(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"},"metadata":{}}]},{"source":"# reshape: add an extra dimension\nx_reshaped = x.reshape(2,5) #working because 2*5 = 10\nx_reshaped, x_reshaped.shape","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# reshape: add an extra dimension\nx_reshaped = x.reshape(2,5) #working because 2*5 = 10\nx_reshaped, x_reshaped.shape"},"cell_type":"code","id":"6157ad09-4b62-400b-897a-5f09f396c57e","execution_count":427,"outputs":[{"output_type":"execute_result","execution_count":427,"data":{"text/plain":"(tensor([[ 1.,  2.,  3.,  4.,  5.],\n         [ 6.,  7.,  8.,  9., 10.]]),\n torch.Size([2, 5]))"},"metadata":{}}]},{"source":"# change the view (changing z changes x)\nz = x.view(1,10)\nz[:,0] = 5\nx, z, z.shape","metadata":{"executionTime":10,"lastSuccessfullyExecutedCode":"# change the view (changing z changes x)\nz = x.view(1,10)\nz[:,0] = 5\nx, z, z.shape"},"cell_type":"code","id":"05a05d4c-a86c-4214-8ee2-df5a926e430c","execution_count":428,"outputs":[{"output_type":"execute_result","execution_count":428,"data":{"text/plain":"(tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n torch.Size([1, 10]))"},"metadata":{}}]},{"source":"# stack tensors on top of each other\ndim=1\nx_stacked = torch.stack([x,x,x,x], dim=dim)\nx_stacked, x_reshaped.shape","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# stack tensors on top of each other\ndim=1\nx_stacked = torch.stack([x,x,x,x], dim=dim)\nx_stacked, x_reshaped.shape"},"cell_type":"code","id":"460b77c8-e415-4808-8d1e-e900763f1537","execution_count":429,"outputs":[{"output_type":"execute_result","execution_count":429,"data":{"text/plain":"(tensor([[ 5.,  5.,  5.,  5.],\n         [ 2.,  2.,  2.,  2.],\n         [ 3.,  3.,  3.,  3.],\n         [ 4.,  4.,  4.,  4.],\n         [ 5.,  5.,  5.,  5.],\n         [ 6.,  6.,  6.,  6.],\n         [ 7.,  7.,  7.,  7.],\n         [ 8.,  8.,  8.,  8.],\n         [ 9.,  9.,  9.,  9.],\n         [10., 10., 10., 10.]]),\n torch.Size([2, 5]))"},"metadata":{}}]},{"source":"Note on \"dim\" values: \n- For a 1-dimensional tensor (i.e., a vector), dim can only be 0.\n- For a 2-dimensional tensor (i.e., a matrix), dim can be 0 or 1.\n- For tensors with more than 2 dimensions, dim can be any integer from 0 to n-1, where n is the number of dimensions in the tensor.\n","metadata":{},"cell_type":"markdown","id":"b2956f2c-6e7a-437c-a67e-fefc9b3ad990"},{"source":"# torch squeeze - remove dimensions of size 1\n\n# Create a tensor with a singleton dimension\na = torch.rand(3, 1, 4)\n\n# Squeeze the tensor to remove the singleton dimension\nb = torch.squeeze(a)\n\n# Print the shapes of the tensors\nprint(a.shape)  # Output: torch.Size([3, 1, 4])\nprint(b.shape)  # Output: torch.Size([3, 4])\nprint(a)\nprint(b)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# torch squeeze - remove dimensions of size 1\n\n# Create a tensor with a singleton dimension\na = torch.rand(3, 1, 4)\n\n# Squeeze the tensor to remove the singleton dimension\nb = torch.squeeze(a)\n\n# Print the shapes of the tensors\nprint(a.shape)  # Output: torch.Size([3, 1, 4])\nprint(b.shape)  # Output: torch.Size([3, 4])\nprint(a)\nprint(b)"},"cell_type":"code","id":"43fe540c-f98d-4595-a4ba-f895ef298bfb","execution_count":430,"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([3, 1, 4])\ntorch.Size([3, 4])\ntensor([[[0.5194, 0.5337, 0.7050, 0.3362]],\n\n        [[0.7891, 0.1694, 0.1800, 0.7177]],\n\n        [[0.6988, 0.5510, 0.2485, 0.8518]]])\ntensor([[0.5194, 0.5337, 0.7050, 0.3362],\n        [0.7891, 0.1694, 0.1800, 0.7177],\n        [0.6988, 0.5510, 0.2485, 0.8518]])\n"}]},{"source":"# torch unsqueeze - add a new dimension or axis with a length of 1\nc = torch.unsqueeze(b, dim=1)\nc, c.shape","metadata":{"executionTime":9,"lastSuccessfullyExecutedCode":"# torch unsqueeze - add a new dimension or axis with a length of 1\nc = torch.unsqueeze(b, dim=1)\nc, c.shape"},"cell_type":"code","id":"e27b3c5f-46ae-45b4-b193-c06848373d7b","execution_count":431,"outputs":[{"output_type":"execute_result","execution_count":431,"data":{"text/plain":"(tensor([[[0.5194, 0.5337, 0.7050, 0.3362]],\n \n         [[0.7891, 0.1694, 0.1800, 0.7177]],\n \n         [[0.6988, 0.5510, 0.2485, 0.8518]]]),\n torch.Size([3, 1, 4]))"},"metadata":{}}]},{"source":"# torch permute dimension\nx = torch.randn(2, 3, 5)\nx.size(), torch.permute(x, (2, 0, 1)).size()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# torch permute dimension\nx = torch.randn(2, 3, 5)\nx.size(), torch.permute(x, (2, 0, 1)).size()"},"cell_type":"code","id":"7cc2ebed-6728-48f6-b3ef-853d4a9b8a2b","execution_count":432,"outputs":[{"output_type":"execute_result","execution_count":432,"data":{"text/plain":"(torch.Size([2, 3, 5]), torch.Size([5, 2, 3]))"},"metadata":{}}]},{"source":"## Tensor indexing","metadata":{},"cell_type":"markdown","id":"96a2c6f7-8b7e-4bee-96d7-1cbfe0cb9957"},{"source":"# basic indexing - access individual elements of a tensor\nx = torch.tensor([1, 2, 3])\nprint(x[0])   # output: tensor(1)","metadata":{"executionTime":9,"lastSuccessfullyExecutedCode":"# basic indexing - access individual elements of a tensor\nx = torch.tensor([1, 2, 3])\nprint(x[0])   # output: tensor(1)"},"cell_type":"code","id":"36661551-0a45-4907-891c-2af1047568c7","execution_count":433,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor(1)\n"}]},{"source":"# slicing: slice a tensor to extract a subset of its elements\nx = torch.tensor([1, 2, 3, 4, 5])\nprint(x[1:4])   # output: tensor([2, 3, 4])","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# slicing: slice a tensor to extract a subset of its elements\nx = torch.tensor([1, 2, 3, 4, 5])\nprint(x[1:4])   # output: tensor([2, 3, 4])"},"cell_type":"code","id":"29a69224-967b-4ba9-99f3-1b55ffa4caa7","execution_count":434,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([2, 3, 4])\n"}]},{"source":"#advanced indexing: advanced indexing to select specific elements of a tensor based on their indices\nx = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n(x[0]), x[0,1], x[0,2,0], x[:, :, 1], x[:,1,2], x[:,:,2]","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"#advanced indexing: advanced indexing to select specific elements of a tensor based on their indices\nx = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n(x[0]), x[0,1], x[0,2,0], x[:, :, 1], x[:,1,2], x[:,:,2]"},"cell_type":"code","id":"51a32f97-54ab-496c-9b81-345dd97e1880","execution_count":435,"outputs":[{"output_type":"execute_result","execution_count":435,"data":{"text/plain":"(tensor([[1, 2, 3],\n         [4, 5, 6],\n         [7, 8, 9]]),\n tensor([4, 5, 6]),\n tensor(7),\n tensor([[2, 5, 8]]),\n tensor([6]),\n tensor([[3, 6, 9]]))"},"metadata":{}}]},{"source":"## PyTorch tensors and NumPy","metadata":{},"cell_type":"markdown","id":"c1b0e5b5-79c6-4e66-98f3-aca8455b17c5"},{"source":"PyTorch tensors and NumPy arrays are both used for numerical computing and data analysis, but they have some differences in terms of their features and functionalities.\n\nPyTorch is a popular deep learning framework that uses tensors as the primary data structure for numerical computations. Tensors in PyTorch are similar to multi-dimensional arrays in NumPy, but they are designed to work efficiently with deep learning models and GPU acceleration. PyTorch tensors have many similarities with NumPy arrays in terms of indexing, slicing, and broadcasting, making it easy to integrate PyTorch with other Python libraries such as NumPy, SciPy, and Pandas.\n\nOne of the key differences between PyTorch tensors and NumPy arrays is that PyTorch tensors can be used with GPU acceleration, which can significantly speed up computations for deep learning models. In contrast, NumPy arrays are typically limited to CPU computations, although there are some libraries such as CuPy that can provide GPU acceleration for NumPy.\n\nAnother difference between PyTorch tensors and NumPy arrays is that PyTorch tensors can be easily converted to and from NumPy arrays using the torch.from_numpy() and torch.Tensor.numpy() functions. This makes it easy to integrate PyTorch with existing NumPy-based workflows and codebases.\n\nFinally, PyTorch tensors have some additional features compared to NumPy arrays that make them well-suited for deep learning tasks. For example, PyTorch provides a built-in autograd system for automatic differentiation, which allows for efficient computation of gradients and backpropagation in deep learning models. PyTorch also provides a rich set of functions and modules for building and training deep learning models, such as convolutional and recurrent neural networks, as well as support for distributed computing and deployment on different platforms.\n","metadata":{},"cell_type":"markdown","id":"e544abf8-7e16-46e3-b730-a35b94c94fc5"},{"source":"# NumPy array to tensor\narray = np.arange(1.0,8.0) #deafult dtype is float64\ntensor = torch.from_numpy(array).type(torch.float32)\narray, tensor, tensor.dtype","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# NumPy array to tensor\narray = np.arange(1.0,8.0) #deafult dtype is float64\ntensor = torch.from_numpy(array).type(torch.float32)\narray, tensor, tensor.dtype"},"cell_type":"code","id":"756e229c-329a-4b79-a217-cbd88b17665c","execution_count":436,"outputs":[{"output_type":"execute_result","execution_count":436,"data":{"text/plain":"(array([1., 2., 3., 4., 5., 6., 7.]),\n tensor([1., 2., 3., 4., 5., 6., 7.]),\n torch.float32)"},"metadata":{}}]},{"source":"# change the value of array\narray = array + 1\narray, tensor","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# change the value of array\narray = array + 1\narray, tensor"},"cell_type":"code","id":"b7f1dba5-d9fe-40f1-a917-617052e464a3","execution_count":437,"outputs":[{"output_type":"execute_result","execution_count":437,"data":{"text/plain":"(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"},"metadata":{}}]},{"source":"# tenson to numpy array\ntensor = torch.ones(7)\nnumpy_tensor = tensor.numpy().astype(np.float64) #if not specified, the type will be tensor's type float32\ntensor, numpy_tensor, numpy_tensor.dtype","metadata":{"executionTime":50,"lastSuccessfullyExecutedCode":"# tenson to numpy array\ntensor = torch.ones(7)\nnumpy_tensor = tensor.numpy().astype(np.float64) #if not specified, the type will be tensor's type float32\ntensor, numpy_tensor, numpy_tensor.dtype"},"cell_type":"code","id":"d47d3729-75a5-4e2c-8fd7-0510f2d225f2","execution_count":438,"outputs":[{"output_type":"execute_result","execution_count":438,"data":{"text/plain":"(tensor([1., 1., 1., 1., 1., 1., 1.]),\n array([1., 1., 1., 1., 1., 1., 1.]),\n dtype('float64'))"},"metadata":{}}]},{"source":"# change the tensor\ntensor = tensor + 1\ntensor, numpy_tensor","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# change the tensor\ntensor = tensor + 1\ntensor, numpy_tensor"},"cell_type":"code","id":"821934de-6261-4a3e-961d-81b4b7409c58","execution_count":439,"outputs":[{"output_type":"execute_result","execution_count":439,"data":{"text/plain":"(tensor([2., 2., 2., 2., 2., 2., 2.]), array([1., 1., 1., 1., 1., 1., 1.]))"},"metadata":{}}]},{"source":"## PyTorch reproducibility","metadata":{},"cell_type":"markdown","id":"4b2f4fb7-c1ec-4cc6-91be-84c3eaa90723"},{"source":"Reproducibility is an important aspect of deep learning research, as it allows other researchers to verify and build upon previously published results. \nSetting random seeds for the random number generators used in the code ensures that the same random numbers are generated every time the code is run. ","metadata":{},"cell_type":"markdown","id":"5f22bdec-9783-4b3c-83aa-79dacdaddf24"},{"source":"# create two random tensors\nrandom_tensor_A = torch.rand(3,4)\nrandom_tensor_B = torch.rand(3,4)\nrandom_tensor_A, random_tensor_B, random_tensor_A == random_tensor_B","metadata":{"executionTime":7,"lastSuccessfullyExecutedCode":"# create two random tensors\nrandom_tensor_A = torch.rand(3,4)\nrandom_tensor_B = torch.rand(3,4)\nrandom_tensor_A, random_tensor_B, random_tensor_A == random_tensor_B"},"cell_type":"code","id":"2eb2056d-912d-4bd4-8b45-40621400df49","execution_count":440,"outputs":[{"output_type":"execute_result","execution_count":440,"data":{"text/plain":"(tensor([[0.7900, 0.2483, 0.8160, 0.1168],\n         [0.9158, 0.9107, 0.8897, 0.5155],\n         [0.5067, 0.7787, 0.9570, 0.2658]]),\n tensor([[0.6693, 0.7904, 0.1429, 0.2596],\n         [0.3507, 0.6683, 0.4601, 0.9545],\n         [0.1936, 0.8199, 0.3752, 0.6261]]),\n tensor([[False, False, False, False],\n         [False, False, False, False],\n         [False, False, False, False]]))"},"metadata":{}}]},{"source":"# create random but reproducible tensors\n\nRANDOM_SEED = 42\n\ntorch.manual_seed(RANDOM_SEED)\nrandom_tensor_C = torch.rand(3,4)\n\ntorch.manual_seed(RANDOM_SEED)\nrandom_tensor_D = torch.rand(3,4)\n\nrandom_tensor_C, random_tensor_D, random_tensor_C == random_tensor_D","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# create random but reproducible tensors\n\nRANDOM_SEED = 42\n\ntorch.manual_seed(RANDOM_SEED)\nrandom_tensor_C = torch.rand(3,4)\n\ntorch.manual_seed(RANDOM_SEED)\nrandom_tensor_D = torch.rand(3,4)\n\nrandom_tensor_C, random_tensor_D, random_tensor_C == random_tensor_D"},"cell_type":"code","id":"230146df-f242-48e9-8232-478f20a10666","execution_count":441,"outputs":[{"output_type":"execute_result","execution_count":441,"data":{"text/plain":"(tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n         [0.3904, 0.6009, 0.2566, 0.7936],\n         [0.9408, 0.1332, 0.9346, 0.5936]]),\n tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n         [0.3904, 0.6009, 0.2566, 0.7936],\n         [0.9408, 0.1332, 0.9346, 0.5936]]),\n tensor([[True, True, True, True],\n         [True, True, True, True],\n         [True, True, True, True]]))"},"metadata":{}}]},{"source":"## Runnig on GPUs","metadata":{},"cell_type":"markdown","id":"d448a258-25ef-436e-8f59-9a116d67fa07"},{"source":"A GPU (Graphics Processing Unit) is a specialized processor designed for handling complex graphical computations, such as those required for 3D graphics, image and video processing, and scientific simulations. GPUs are highly parallelized, meaning they can handle multiple calculations at the same time, making them particularly useful for tasks that involve large amounts of data.\n\nIn general, GPUs are faster than CPUs when it comes to tasks that involve large amounts of data or complex calculations. However, CPUs are better suited for tasks that require a high degree of flexibility or that involve multiple types of calculations.\n\nWhen it comes to choosing between a GPU and a CPU, it ultimately depends on the specific task or application. For tasks that involve heavy graphical computations, such as gaming or video editing, a GPU is likely to be the better choice. For more general computing tasks, such as browsing the web or word processing, a CPU is likely to be sufficient.","metadata":{},"cell_type":"markdown","id":"73104707-b2ef-4776-88ca-0241fb35f0f4"},{"source":"From where you can get GPU?\n1. use google colab\n2. use your own GPU (see this post https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/)\n3. use cloud computing - GCP, AWS, Azure","metadata":{},"cell_type":"markdown","id":"40fc2d9f-09b9-4e86-bb7b-1a77948078b2"},{"source":"# check the GPU access\ntorch.cuda.is_available()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# check the GPU access\ntorch.cuda.is_available()"},"cell_type":"code","id":"8b68c349-56df-4129-9ca7-2a6447049dcd","execution_count":442,"outputs":[{"output_type":"execute_result","execution_count":442,"data":{"text/plain":"False"},"metadata":{}}]},{"source":"# setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"executionTime":75,"lastSuccessfullyExecutedCode":"# setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice"},"cell_type":"code","id":"5ebe5f11-8f9b-424f-870b-72633e665268","execution_count":443,"outputs":[{"output_type":"execute_result","execution_count":443,"data":{"text/plain":"'cpu'"},"metadata":{}}]},{"source":"# count the number of devices\ntorch.cuda.device_count()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# count the number of devices\ntorch.cuda.device_count()"},"cell_type":"code","id":"4b55c3e0-8591-4fca-9506-a2183dbc7c53","execution_count":444,"outputs":[{"output_type":"execute_result","execution_count":444,"data":{"text/plain":"0"},"metadata":{}}]},{"source":"# putting tensors (and models) on the GPU\n\n# create a tensor (default on CPU)\ntensor = torch.tensor([1,2,2])\n\n# move tensor on GPU (if available)\ntensor_on_gpu = tensor.to(device)\ntensor_on_gpu, tensor_on_gpu.device","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# putting tensors (and models) on the GPU\n\n# create a tensor (default on CPU)\ntensor = torch.tensor([1,2,2])\n\n# move tensor on GPU (if available)\ntensor_on_gpu = tensor.to(device)\ntensor_on_gpu, tensor_on_gpu.device"},"cell_type":"code","id":"9c617f45-e508-436c-b84f-cfc2ad5f04c4","execution_count":445,"outputs":[{"output_type":"execute_result","execution_count":445,"data":{"text/plain":"(tensor([1, 2, 2]), device(type='cpu'))"},"metadata":{}}]},{"source":"# moving tensors back to CPU\n\n# if tensor on GPU, can't transformt it on NumPy\ntensor_on_gpu.numpy()\n\ntensor_back_on_cpu = tensor_on_gpu.cpu()\ntensor_back_on_cpu.numpy()\ntensor_back_on_cpu","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# moving tensors back to CPU\n\n# if tensor on GPU, can't transformt it on NumPy\ntensor_on_gpu.numpy()\n\ntensor_back_on_cpu = tensor_on_gpu.cpu()\ntensor_back_on_cpu.numpy()\ntensor_back_on_cpu"},"cell_type":"code","id":"02937cce-3aca-454d-a0c7-153532e47f78","execution_count":446,"outputs":[{"output_type":"execute_result","execution_count":446,"data":{"text/plain":"tensor([1, 2, 2])"},"metadata":{}}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}